{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import math\n",
    "import shutil\n",
    "from  shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e58f14",
   "metadata": {},
   "source": [
    "# HANDLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'D:\\\\Documents\\\\GMU\\\\Clases\\\\CS747\\\\Assigments\\\\HW2\\\\code\\\\workData\\\\train\\\\'\n",
    "VAL_PATH='D:\\\\Documents\\\\GMU\\\\Clases\\\\CS747\\\\Assigments\\\\HW2\\\\code\\\\workData\\\\validate\\\\'\n",
    "TEST_PATH='D:\\\\Documents\\\\GMU\\\\Clases\\\\CS747\\\\Assigments\\\\HW2\\\\code\\\\workData\\\\test\\\\'\n",
    "\n",
    "DATA_PATH = 'D:\\\\Documents\\\\GMU\\\\Clases\\\\CS747\\\\Assigments\\\\HW2\\\\code\\\\Data\\\\'\n",
    "\n",
    "batch_size = 15 #128\n",
    "epochs = 75\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf1276",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('D:\\\\Documents\\\\GMU\\\\Clases\\\\CS747\\\\Assigments\\\\HW2\\\\code\\\\workData\\\\')\n",
    "os.mkdir(TRAIN_PATH)\n",
    "os.mkdir(VAL_PATH)\n",
    "os.mkdir(TEST_PATH)\n",
    "\n",
    "train_food = os.path.join(TRAIN_PATH, 'food')\n",
    "train_no_food = os.path.join(TRAIN_PATH, 'no_food')\n",
    "\n",
    "val_food = os.path.join(VAL_PATH, 'food')\n",
    "val_no_food = os.path.join(VAL_PATH, 'no_food')\n",
    "\n",
    "test_food = os.path.join(TEST_PATH, 'food')\n",
    "test_no_food = os.path.join(TEST_PATH, 'no_food')\n",
    "\n",
    "os.mkdir(train_food)\n",
    "os.mkdir(train_no_food)\n",
    "\n",
    "os.mkdir(val_food)\n",
    "os.mkdir(val_no_food)\n",
    "\n",
    "os.mkdir(test_food)\n",
    "os.mkdir(test_no_food)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca37578",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_food_list = []\n",
    "train_no_food_list = []\n",
    "\n",
    "for file in os.listdir(DATA_PATH + 'training\\\\'):\n",
    "    if file[:1] == '0':\n",
    "        train_no_food_list.append(file)\n",
    "    elif file[:1] == '1':\n",
    "        train_food_list.append(file)\n",
    "        \n",
    "validate_food_list = []\n",
    "validate_no_food_list = []\n",
    "\n",
    "for file in os.listdir(DATA_PATH + 'validation\\\\'):\n",
    "    if file[:1] == '0':\n",
    "        validate_no_food_list.append(file)\n",
    "    elif file[:1] == '1':\n",
    "        validate_food_list.append(file)\n",
    "        \n",
    "test_food_list = []\n",
    "test_no_food_list = []\n",
    "\n",
    "for file in os.listdir(DATA_PATH + 'evaluation\\\\'):\n",
    "    if file[:1] == '0':\n",
    "        test_no_food_list.append(file)\n",
    "    elif file[:1] == '1':\n",
    "        test_food_list.append(file)\n",
    "\n",
    "        \n",
    "print('Images to train: food ['+str(len(train_food_list))+'] no food ['+str(len(train_no_food_list))+']')\n",
    "print('Images to validate: food ['+str(len(validate_food_list))+'] no food ['+str(len(validate_no_food_list))+']')\n",
    "print('Images to test: food ['+str(len(test_food_list))+'] no food ['+str(len(test_no_food_list))+']')\n",
    "\n",
    "\n",
    "stepPerEpoch = math.ceil((len(train_food_list) + len(train_no_food_list)) / batch_size)\n",
    "\n",
    "print('step per epoch ' + str(stepPerEpoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in train_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'training\\\\', file), os.path.join(train_food, file))\n",
    "for file in train_no_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'training\\\\', file), os.path.join(train_no_food, file))\n",
    "    \n",
    "for file in validate_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'validation\\\\', file), os.path.join(val_food, file))\n",
    "for file in validate_no_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'validation\\\\', file), os.path.join(val_no_food, file))\n",
    "    \n",
    "for file in test_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'evaluation\\\\', file), os.path.join(test_food, file))\n",
    "for file in train_no_food_list:\n",
    "    copyfile(os.path.join(DATA_PATH + 'evaluation\\\\', file), os.path.join(test_no_food, file))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820043c",
   "metadata": {},
   "source": [
    "# Handle manual CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator_no_aumentation = ImageDataGenerator(rescale=0)\n",
    "validation_image_generator = ImageDataGenerator(rescale=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032818b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen_no_aumentation = train_image_generator_no_aumentation.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=TRAIN_PATH,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=VAL_PATH,\n",
    "                                                              shuffle=False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')\n",
    "test_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=TEST_PATH,\n",
    "                                                              shuffle= False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f87173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.3\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(8, 3, padding='same', activation='relu', \n",
    "           input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(dropout),\n",
    "    Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    #Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    #MaxPooling2D(),\n",
    "    Dropout(dropout),\n",
    "    Flatten(), # flat the dimension to fit on dense layers\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac28d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen_no_aumentation,\n",
    "    steps_per_epoch=stepPerEpoch,\n",
    "    epochs=75,\n",
    "    validation_data=val_data_gen,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_gen\n",
    "                                     , verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2928a",
   "metadata": {},
   "source": [
    "# VGG16 without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c366dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator_no_aumentation = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_image_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eeb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen_no_aumentation = train_image_generator_no_aumentation.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=TRAIN_PATH,\n",
    "                                                     shuffle=False,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=VAL_PATH,\n",
    "                                                              shuffle=False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')\n",
    "test_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=TEST_PATH,\n",
    "                                                              shuffle= False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04873642",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "VGG16_model = VGG16(input_shape = IMG_SHAPE,\n",
    "                   include_top=False,\n",
    "                   weights = 'imagenet'\n",
    "                   )\n",
    "for layer in VGG16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    VGG16_model,\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7adfb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268936e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen_no_aumentation,\n",
    "    steps_per_epoch=stepPerEpoch,\n",
    "    epochs=75,\n",
    "    validation_data=val_data_gen,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d833c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a435060",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_gen\n",
    "                                     , verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3a121",
   "metadata": {},
   "source": [
    "# VGG16 with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(\n",
    "                                                preprocessing_function=preprocess_input,\n",
    "                                                rescale=1./255,\n",
    "                                                rotation_range=45,\n",
    "                                                width_shift_range=.15,\n",
    "                                                height_shift_range=.15,\n",
    "                                                horizontal_flip=True,\n",
    "                                                vertical_flip = True,\n",
    "                                                zoom_range=0.3                         \n",
    "                                            ) # Generator for our training data\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=TRAIN_PATH,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=VAL_PATH,\n",
    "                                                              shuffle=False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')\n",
    "test_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=TEST_PATH,\n",
    "                                                              shuffle= False,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "\n",
    "VGG16_model = VGG16(input_shape = IMG_SHAPE,\n",
    "                   include_top=False,\n",
    "                   weights = 'imagenet'\n",
    "                   )\n",
    "for layer in VGG16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    VGG16_model,\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e003ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123baf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410639a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 10)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=stepPerEpoch,\n",
    "    epochs=75,\n",
    "    validation_data=val_data_gen,\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a40c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_data_gen\n",
    "                                     , verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd57d00b",
   "metadata": {},
   "source": [
    "# Space for plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389def3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a bar chart with groups\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set height of bar\n",
    "# length of these lists determine the number\n",
    "# of groups (they must all be the same length)\n",
    "bars1 = [0.9660, 1.0000, 0.9503]\n",
    "bars2 = [0.8410, 0.9810, 0.9700]\n",
    "\n",
    "# set width of bar. To work and supply some padding\n",
    "# the number of groups times barWidth must be\n",
    "# a little less than 1 (since the next group\n",
    "# will start at 1, then 2, etc).\n",
    "\n",
    "barWidth = 0.25\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='green', width=barWidth, edgecolor='white', label='Train')\n",
    "plt.bar(r2, bars2, color='red', width=barWidth, edgecolor='white', label='Validate')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Different accuracies', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], ['CNN of choice', 'VGG16', 'VGG16 with augmentation'])\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()\n",
    "#plt.savefig(\"barChart.pdf\",dpi=400,bbox_inches='tight',pad_inches=0.05) # save as a pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
